---
title: "Final Project"
author: "Veena Advani, Annie Chen, Robert Tung"
date: "Due 4/28/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library("foreign")
library("dplyr")
library("tidyr")
library("countrycode")
library("rworldmap")
library(ggplot2)
library(reshape2)
library(FNN)
library(grid)
library(gridExtra)
library(leaps)
library(GGally)
```

```{r, include=FALSE}
# To start, let's read in the cleaned datasets from our last submission:
teacher_data <- read.csv("TALIS.csv")
subject_data <- read.csv("subject_data.csv", as.is=TRUE)

# Change column names of 10 satisfaction questions to make more readable
satcols <- grep("TT2G46", colnames(teacher_data))
indices <- satcols[satcols != which(colnames(teacher_data) == "TT2G46_avg")]
colnames(teacher_data)[indices] <- c("sat1", "sat2", "sat3", "sat4", "sat5", "sat6", "sat7", "sat8", "sat9", "sat10")
names(teacher_data)[names(teacher_data)=="TT2G46_avg"] <- "sat_avg"

# Column "TT2G15" contains no useful data, since it's all NAs, so we're going to remove it
# Column "ID" is no longer necessary, was used for making the subject dataset
teacher_data <- teacher_data[,-which(names(teacher_data) %in% c("TT2G15","ID"))]

# Change some of the subject names (one of the comments in our dataset submission was that they weren't clear):
names(teacher_data)[names(teacher_data) == "For_Lang"] <- "Modern_Lang"
names(teacher_data)[names(teacher_data) == "Gk_Ln"] <- "Ancient_Lang"

# We also thought it might be useful to have a variable that indicates the number of subjects a given teacher teaches, so let's add it below:
subject_names <- c("R_WR_Lit", "Math", "Science", "Soc_Studies", "Modern_Lang", "Ancient_Lang", "Tech", "Arts", "PE", "Rel_Ethics", "Practical", "Other")
subject_indices <- c(which(colnames(teacher_data) %in% subject_names))

teacher_data$num_subjects <- rowSums(teacher_data[,subject_indices], na.rm=TRUE)

# We discussed in our dataset submission why we weren't going to use their teacher satisfaction variable, and we are instead going to use the average of the 10 satisfaction questions, as a result, let's remove the teacher satisfaction variable:
teacher_data <- teacher_data[, -which(names(teacher_data) %in% c("satisfaction"))]

# A lot of the variables stored as categorical variables with the categories "Strongly Disagree", "Disagree", "Strongly Agree", and "Agree", are currently factors.  Given that these categories do have a natural ordering, we're going to convert them into ordered factors.
teacher_data$prep_A <- factor(teacher_data$prep_A, levels=c("Not at all", "Somewhat", "Well", "Very well"), ordered=TRUE)
teacher_data$prep_B <- factor(teacher_data$prep_B, levels=c("Not at all", "Somewhat", "Well", "Very well"), ordered=TRUE)
teacher_data$prep_C <- factor(teacher_data$prep_C, levels=c("Not at all", "Somewhat", "Well", "Very well"), ordered=TRUE)
teacher_data$feedback_salary <- factor(teacher_data$feedback_salary, levels=c("No positive change", "A small change", "A moderate change", "A large change"), ordered=TRUE)
teacher_data$collab <- factor(teacher_data$collab, levels=c("Strongly disagree", "Disagree", "Agree", "Strongly agree"), ordered=TRUE)

# We'll split the country data into regions using the World Health Organization  categories, so that we can try to find regional patterns

# Brazil, Chile
teacher_data$region[teacher_data$country %in% c("BRA", "CHL")] <- "South America"

# Canada, Mexico, United States
teacher_data$region[teacher_data$country %in% c("CAB", "MEX", "USA")] <- "North America"

#  Bulgaria, Czech Republic,  Poland,  Romania, Russia, Slovak Republic
teacher_data$region[teacher_data$country %in% 
                        c("BGR", "CZE", "POL", "ROU", "RUS", "SVK")] <- "Eastern Europe"

# Denmark, England, Estonia, Finland,   Latvia,  Norway, Sweden
teacher_data$region[teacher_data$country %in% 
                        c("DNK", "ENG",  "EST", "FIN", "LVA", "NOR", "SWE")] <- "Northern Europe"

# Spain, Croatia, Italy, Latvia,  Portugal,  Serbia, 
teacher_data$region[teacher_data$country %in% 
                        c("ESP", "HRV", "ITA", "LVA", "PRT", "SRB")] <- "Southern Europe"

# Belgium,  France, Netherlands
teacher_data$region[teacher_data$country %in% 
                        c("BFL", "FRA","NLD")] <- "Western Europe"

# Abu Dhabi, Georgia, Israel                     
teacher_data$region[teacher_data$country %in% c("AAD", "GEO", "ISR")] <- "East Mediterranean"

# Australia, China, Japan, South Korea, Malaysia, New Zealand, Singapore
teacher_data$region[teacher_data$country %in% c("AUS", "CSH", "JPN", "KOR", "MYS", "NZL", "SGP")] <- "Western Pacific"

teacher_data$region <- as.factor(teacher_data$region)
```

# Introduction

  This analysis will focus on the Teaching and Learning International Survey (TALIS) Dataset. This data set was coordinated by the Organization for Economic Cooperation and Development (OECD), an intergovernmental organization of industrialized countries. The TALIS dataset comes from a survey of the teaching workforce that aims to collect information about teaching as a profession, the working conditions of teachers, and the learning environments of schools. Another goal of the TALIS survey was to provide a more global view of education systems, and to produce metrics that could be used to compare education systems from different countries.  
  TALIS was administered in 2008 and 2013. We will be using the more recent international dataset, from 2013.  It contains answers from teachers from more than 10,000 schools in 36 different countries. It's worth noting that not all of the countries were English speaking, and that the only requirement for each participating country was that it must be industrialized.  The TALIS dataset contains several different files.  The data is split by school type (primary school, secondary school etc).  Although the TALIS dataset contains information from a variety of school types (primary, secondary, etc), the focus of the survey was on lower-secondary schools, and that is the largest data file.  As a result, we are going to focus our analysis on lower-secondary schools.  At each school that was selected to participate, the principal (or head administrator) and a random selection of up to 22 teachers were chosen to complete voluntary online questionnaires.  Our analysis below consists of only the teacher responses, not the responses of the principals, as they were given slightly different questionnaires.
  The first question we hope to explore in our analysis, is:
  (1) Which variables and classroom factors are the best predictors of teacher job satisfaction?
  There are several reasons motivating this question.  Education is incredibly important to any countries development and functioning.  It's important that a country can educate it's youth, so that they can participate in society when they are adults.  However, there is a fair amount of diversity across countries with regard to how well the teaching profession is respected, and how well education systems are funded.  As a result, teacher working conditions vary quire a bit.  However, in order to make sure that there are enough teachers, and that they are able to teach their students well, it is important to make sure that teacher satisfaction is at a high enough level.  If teacher satisfaction is too low, it becomes difficult to retain a large enough teaching force, and to attract talented people to the field.  Low teacher satisfaction can also indicate that they are having trouble doing their job well, possibly due to environmental factors out of their control.  For many reasons such as these, teacher satisfaction is a useful metric to observe in any education system.  It's also helpful to understand what kinds of environments keep teachers more satisfied, so that educational systems can encourage and build these types of environments.  Therefore, understanding how teacher satisfaction varies across the 36 countries in the data set, and which aspects of a school and environment correlate most with teacher satisfaction, could be helpful information.
  Our second research question is:
  (2) How do teacher satisfaction, as well as some of the significant predictors found from question 1, vary by country?

#### Main Research Questions:
(1) Which variables and classroom factors are the best predictors of teacher job satisfaction?
(2) How do teacher satisfaction, as well as some of the significant predictors found from question 1, vary by country?

#### Motivation of Study:
* Education is important to any country's basic development and functioning
* There is a fair amount of diversity across countries with regard to how well the teaching profession is respected, as well as how much countries fund their education systems.
* As a result, teacher working conditions vary quite a bit
* However, in order to make sure that there are enough teachers, and that they are able to teach their students well, it is important that teacher satisfaction is at a high enough level.  If teacher satisfaction is too low, it becomes difficult to retain a large enough teaching force
* Therefore, understanding how teacher satisfaction varies across the 36 countries in the data set, and which aspects of a school and environment correlate most with teacher satisfaction, could be helpful information in order to make sure that countries have enough teachers, and that teachers have enough resources to do their jobs well.

# Data

Each row of the dataset is for a single teacher's response to the questionnaire (There are 117876 rows).  Each column in the dataset corresponds to either a particular question in the questionnaire, or a summary variable for a section of the questionnaire.

The dataset contains a column for each individual question on the questionnaire, and summary columns for overall sections. For example, there are individual columns for questions such as “The advantages of this profession clearly outweigh the disadvantages” and “I would recommend my school as a good place to work”, but also an overall column summing up all the scores for the teacher satisfaction questions. Each row of the dataset is for a different teacher’s responses to the questionnaire.  Almost all of the questions in the questionnaire were multiple choice or numerical input questions.  

The dataset contains a column for each individual question on the questionnaire, and summary columns for overall sections. There are columns concerning employment status, personal information/background, time spent, professional development, efficacy and amount of feedback, outlook about the school, school climate, overall job satisfaction, and much more. Each row of the dataset is for a different teacher’s responses to the questionnaire.  Almost all of the questions in the questionnaire were multiple choice or numerical input questions.  

The variables we are using are:

* `country (CNTRY):` Country of teacher (factor variable, 36 levels)
* `region:` Region the teacher's country is in (factor variable, 8 levels)
* `gender (TT2G01):` Teacher Gender (factor variable, 2 levels)
* `age (TT2G02):` Teacher Age (numeric variable)
* `years_teacher (TT2G05B):` Years of teaching experience (numeric variable)
* `train_stat (TT2G11):` Training level of teacher (factor variable)
* `prep_A/B/C (TT2G13A/B/C):` How prepared the teacher felt (factor variable, 4 levels)
* `total_time (TT2G16):` Total time spent on teaching related activities in hours per week (numeric variable)
* `feedback_salary (TT2G30G):` Whether performance feedback influences salary (factor variable, 4 levels)
* `collab (TT2G44E):` How collaborative is the school culture? (factor variable, 4 levels)
* `num_students (TT2G38):` Number of students in the teacher’s class (numeric variable)
* `satisfaction (TJOBSATS):` Self rated teacher job satisfaction (factor variable, 4 levels)
* `Various Subject Names (TT2G15[A - L]):` 12 columns representing which subjects the teacher teaches (boolean numeric variable)
* `num_subjects:` The number of subjects the teacher teaches (numeric variable)
* `sat1-sat10 (TT2G46[A - J]):` Ten questions related to teacher job satisfaction (factor variables, 4 levels)
* `sat_avg:` An average of the ten questions related to teacher job satisfaction (numeric variable)

# Analysis

#### Initial Plots Describing Data

Below are three plots that show our data and hopefully motivate our research questions and the analysis.
```{r, warning=FALSE, echo=FALSE}
# Histogram of teacher satisfaction
p1 <- teacher_data %>% ggplot(aes(x=sat_avg)) + geom_histogram(binwidth = 0.2) + labs(title="Plot 1: Histogram of Teacher Satisfaction", x="Teacher Satisfaction (low to high)", y="Count")

# Boxplot of whether they consider their school a collaborative environment to satisfaction
p2 <- teacher_data %>% filter(!is.na(collab)) %>% ggplot(aes(x=collab, y=sat_avg)) + geom_boxplot() +
  labs(title="Plot 2: Relationship Between Collaboration Level
       of the School and Teacher Satisfaction",
       x="Response to 'There is a collaborative school culture
       which is characterised by mutual support'",
       y="Teacher Satisfaction")

# Boxplot of region to satisfaction
p3 <- teacher_data %>% filter(!is.na(sat_avg)) %>% ggplot(aes(x=reorder(region, -sat_avg, median), y=sat_avg)) + geom_boxplot() + labs(title="Plot 3: Teacher Satisfaction by Region", x="Region", y="Teacher Satisfaction")
```

```{r, echo=FALSE, fig.height=2.25, fig.width=10, message=FALSE, warning=FALSE}
grid.arrange(p1, p2, ncol=2)
```

```{r, echo=FALSE, fig.height=2.25, fig.width=9}
p3
```

**Plot 1** provides a full histogram of teacher satisfaction. As we are later analyzing the effect of different variables on teacher satisfaction, and the variation between different regions, it is important to note the overall distribution of the data. 

**Plot 2** provides a box plot of collab vs sat_avg. This plot is an example of one we would find in regard to our first research question, in which we assess which variables are particularly predictive of overall teacher satisfaction. In looking at this particular plot, we can actually see a strong visual trend between how collaborative a teacher viewed his/her school environment to be, and how satisfied that teacher was. We will provide similar plots for other variables in the analysis of our first research question, as well as more rigorous analysis to be described below.

**Plot 3** provides a box plot of geographic region vs sat_avg. This is relevant to our second research question, which revolves around variations in sat_avg and other variables across different geographical regions. Visually, while all median values for sat_avg hover around the range of 2.5 to 3.5, there is still a noticeable difference in some of the distributions (e.g. the median and both quartiles of the satisfaction value for North America is noticeably above that of Eastern Europe). We will explore additional plots like this one, but with other variables, in our full analysis.

### Removal of Strange Values
QUESTION: should we do this? strange years_teacher values, vs age, or in general, total_time spent per week etc.  Are these all rows we should get rid of???

Before we analyze the data any further, we should clean up the data slightly more.  In previous assignments, we cleaned the dataset with respect to missing values and obvious errors.  However, when considering the context of some of our variables, some of the entries are still unusual.  We have decided to remove these datapoints, since they are likely unreliable.

The total time spent on teaching related activities per week:
```{r}
teacher_data %>% ggplot(aes(x=total_time)) + geom_histogram() + labs(title="Histogram of Time Spent on Teaching Activities per Week", x="Time Spent on Teaching Activities (hrs/week)", y="Count")
```
We can see from this histogram, that there are some teachers claiming to have spent over 90 hours per week on teaching related activities.  Even if a teacher worked from 6 am to 9 pm Monday through Friday (15 hours a day), and another 15 hours of related teaching activities on the weekend, they would be at 90 hours in a week.  Although it's possible teachers at boarding schools might be able to claim this kind of time comittment, other than that it's highly improbable.  We can see that there's a pretty big drop off in the histogram after 60 hours a week.  Given that greater than 90 hours a week seems almost impossible to do, let's see how many teachers reported such a statistic
```{r}
length(teacher_data[teacher_data$total_time>90 & !is.na(teacher_data$total_time),]$total_time)
```
This is not a huge amount of entries given the total size of the dataset, so we are going to remove them.
QUESTION: pretty large difference between doing >= 90, and 90, remove an additional 500 values roughly if you do >=90.
```{r}
teacher_data <- teacher_data[teacher_data$total_time < 90,]
```

We can now take a look at reported age vs years teaching. 
```{r}
teacher_data %>% ggplot(aes(x=age, y=years_teacher)) + geom_point(alpha=0.5,shape=".") + geom_abline(intercept =0, slope=1, color="red") +  geom_abline(intercept = -10, slope=1, color="yellow")+  geom_jitter(shape=".") + labs(title="Reported Age vs Years Teaching", x="Age (years)", y="Years Teaching (years)")
```

We can see that there are points above the red line, which are teachers who reported they had been teaching longer than they had been alive. Indeed, let's see how many responses reported years that would indicate that they had started teaching before age 11 (points above the yellow line), and remove those values.

```{r}
age_start <- teacher_data$age - teacher_data$years_teacher
nrow(teacher_data[age_start <= 11,])
teacher_data <- teacher_data[which(age_start >= 11),]
```

### Analysis for Research Question 1

To address our first research question, and to try to identify which variables are the best indicators of teacher job satisfaction, we are going to attempt to use several techniques.

#### Linear Regression Analysis
Although our earlier plot of satisfaction against the degree of collaboration at the school shows a clear linear trend, let's look at a matrix of plots of the data, before diving into any linear regression models:
```{r}
#ggpairs(teacher_data)
```


(1) We are first going to run two linear regression models: one with all of the predictors in the dataset, and one with all of the predictors that have NA values in less than 5% of observations.
(2) We are going to use forward, backward and bidirectional stepwise selection, and look at the linear models that end up getting chosen from those three methods.
(3) We will then look at which predictors appeared to be the most significant in the linear models from (1) and (2).  



```{r}
# In order to have easier control over which predictors to use in our model, below we create several lists of indices that we might want to include or exclude as a group

# We don't want to use the 10 satisfaction questions to predict satisfaction, so let's create a list of the indices we need to avoid
satcols <- grep("sat", colnames(teacher_data))
sat_indices <- satcols[satcols != which(colnames(teacher_data) == "sat_avg")]

subject_names <- c("R_WR_Lit", "Math", "Science", "Soc_Studies", "Modern_Lang", "Ancient_Lang", "Tech", "Arts", "PE", "Rel_Ethics", "Practical", "Other")
subject_indices <- c(which(colnames(teacher_data) %in% subject_names))

# Some columns also have many more NA values, lets make a list of those so we can choose whether or not to include them in our linear models
na_cols <- c()
for(i in 1:ncol(teacher_data)) {
  if(sum(is.na(teacher_data[,i]))/nrow(teacher_data) > 0.10) {
    na_cols <- c(na_cols,i)
  }
}
```

## added a small plot of numerical variables against sat_avg, in case we want justification for squaring something (I got improvements in r^2 when squaring total_time and years_teacher)
teacher_data[, -c(sat_indices, na_cols, subject_indices,1, 37)] %>%
  gather(-sat_avg, -gender, key = "var", value = "value") %>%
  ggplot(aes(x = value, y = sat_avg, color = gender)) +
    geom_point(alpha=0.05) +
    facet_wrap(~ var, scales = "free") +
    theme_bw()


# For the linear model with most of the predictors, let's remove the columns with a large number of NA values.  
# Let's also remove the columns that correspond to the 10 satisfaction questions, since they were used to create the sat_avg variable (our response variable)
Dataset for Linear Regression Model:
For our linear regression model, we are going to remove columns with a large number of NAs, the subject data columns (we're only interested in the number of subjects each teacher is teaching, not the specific subjects), and the 10 satisfaction related questions, as they were used to create our resposne variable.
```{r}
x <- na.omit(teacher_data[, -c(sat_indices, na_cols, subject_indices)])
```

Now, we are interested in how geography impacts teacher satisfaction, however we have two different geography variables.  We can't include both in the model, as they are linearly dependent, and R will only find a set of coefficients for one of the two variables if we put both in the model.  Because of this, let's try both and compare the results:

Linear model using country:
```{r}
# Try model with country variable and not region
m_country <- lm(sat_avg ~ ., data=x[,-which(names(x) %in% c("region"))])
summary(m_country)
```

Linear model using region:
```{r}
# Try model with region variable and not country
m_region <- lm(sat_avg ~ ., data=x[,-which(names(x) %in% c("country"))])
summary(m_region)
```

We can see from the two summaries, that a large amount of the country categories are significant, and all of the region categories are also significant.  However, the R-squared value for the model using country data was 0.2449, and the R-squared value for the model with the region predictor was 0.1981.  This means that removing some geographical information by condensing the countries into regions caused a drop in R-squared by roughly 19%, which is quite a bit.  As a result, we are going to use the country data in the linear model.

We can also see that train_stat was not significant in either of the models, so let's also remove that from future models.

```{r}
#NOTE: SHOULD REALLY RECREATE ORIGINAL X, MIGHT GET SOME OLD DATA BACK...
x.new <- x[, -which(names(x) %in% c("region", "train_stat"))]
```

Now let's see if all of the variables we have in our dataset are normally distributed, or if some transformations might be helpful:

```{r}
#QUESTION: What is error I'm getting in second plot?
#QUESTION: to justify doing transformations on predictors, do you use histogram of predictor, or graph of predictor against repsonse variable?
x.new %>% ggplot(aes(x=sat_avg)) + geom_histogram(binwidth = 0.2) + labs(title="Histogram of Teacher Satisfaction", x="Teacher Satisfaction (low to high)", y="Count")
```
We can see from the histogram of sat_avg above, that although it isn't perfectly normal, it is close enough that it probably doesn't warrant any transformation of the variable. Additionally, after we have a final model, we can check the qqnorm plot to make sure none of the normality assumptions are drastically violated.

```{r}
#QUESTION: is there a way to do a histogram of all the variables in x?
x.new %>% ggplot(aes(x=total_time)) + geom_histogram() + labs(title="Histogram of Time Spent on Teaching Activities", x="Time Spent on Teaching Related Activities", y="Count")
x.new %>% ggplot(aes(x=years_teacher)) + geom_histogram() + labs(title="Histogram of Years Spent as a Teacher", x="Years of Teaching Experience", y="Count")
```
Both of these histograms, although not perfectly normal, also don't have a huge amount of skew.  In fact, the histogram for time spent on reaching related activities has very little skew.  As a result, we probably don't need to transform either of these variables either.

Model without train_stat:
```{r}
m_final <- lm(sat_avg ~ ., data=x.new)
summary(m_final)
```

Before analyzing this model, let's make sure that the assumptions for linear regression hold.
```{r}
plot(m_final)
```

Now let's analyze the coefficients of the model.  We can see from the summary of m_final, that a lot of the coefficients have statistically significant p-values.  However, this is somewhat expected given the large size of our dataset.  In order to decide which predictors seem to be particularly helpful in predicting teacher satisfaction, let's look at the magnitude of the coefficients, and the confidence intervals of the coefficients and see how far away they are from zero.


Using stepwise regression
```{r}
# Remove SAT questions, since they obviously explain our predictor variable, and then remove NAs for stepwise regression
# Also remove subject columns, we have a column that counts the number of subjects each teacher is teaching, to represent this information instead.
m.full <- lm(sat_avg ~., data=x[,-which(names(x) %in% c("region"))])
m.empty <- lm(sat_avg ~ 1, data=x)
```

Forward, backwards, and both
```{r}
# With AIC
m.forward.aic <- step(m.empty, scope=list(upper=m.full),
                  data=x, direction="forward", trace=FALSE)
m.backward.aic <- step(m.full, scope=list(lower=m.empty),
                  data=x, direction="backward", trace=FALSE)
m.both.aic <- step(m.empty, scope=list(upper=m.full),
                  data=x, direction="both", trace=FALSE)

# With BIC
m.forward.bic <- step(m.empty, scope=list(upper=m.full),
                  data=x, direction="forward", trace=FALSE, k=log(nrow(x)))
m.backward.bic <- step(m.full, scope=list(lower=m.empty),
                  data=x, direction="backward", trace=FALSE, k=log(nrow(x)))
m.both.bic <- step(m.empty, scope=list(upper=m.full),
                  data=x, direction="both", trace=FALSE, k=log(nrow(x)))
```

We can see from the results above, that with AIC as the criterion, all three stepwise models resulted in using the same 9 predictors, which were: collab, country, prep_A, prep_B, prep_C, gender, age, total_time, and years_teacher.

Using the BIC criterion, all three models ended up using all of the same predictors as the AIC stepwise models, except without prep_A.

```{r}
# m3 <- regsubsets(sat_avg ~ ., data=x, nbest=1, method="exhaustive")
```

NOTE: need conclusion to this section!!!

### Analysis for Research Question 2

To address our second research question, and try to identify the differences across different regions for teacher job satisfaction and other classroom factors, we are going to try several techniques.

#### Plots

(1) We are first going to plot sat_avg vs region, using the region variable as a factor. This will visually tell us whether there might be a significant difference in satisfaction across regions.

```{r}
## p3, used as an example plot earlier in this write-up, is a plot of sat_avg vs region
## will fix labels once we figure out how big it can be in the final writeup
p3
```

As we stated above, visually, while all median values for sat_avg hover around the range of 2.5 to 3.5, there is still a noticeable difference in some of the distributions (e.g. the median and both quartiles of the satisfaction value for North America is noticeably above that of Eastern Europe). However, we would classify each region's average as "satisfied", as it falls above 2.5

(2) We are going to plot each of the predictive factors that were found to be significant in Research Question 1 against region, to see if perhaps the region is affecting these variables and thus affecting satisfaction indirectly. These variables are collab, country, prep_A, prep_B, prep_C, gender, age, total_time, and years_teacher. We will not, however, talk about country because of the obvious correlation between that and region.

*note, I don't think it makes sense to plot by decreasing median here, because then you have to see which regions are switching manually. Perhaps we should keep them in alphabetical order or color code or something? Although actually without na.omit, the reordering doesn't work anyway*

```{r}
# Collab plot
c1 <- teacher_data %>% filter(!is.na(collab)) %>% ggplot(aes(x=reorder(region, -as.numeric(collab), median), y=as.numeric(collab))) + geom_boxplot() + xlab("Region") + ylab("Collab")

# prep_A plot
c2 <- teacher_data %>% filter(!is.na(prep_A)) %>% ggplot(aes(x=reorder(region, -as.numeric(prep_A), median), y=as.numeric(prep_A))) + geom_boxplot() + xlab("Region") + ylab("prep_A")

# prep_B plot
c3 <- teacher_data %>% filter(!is.na(prep_B)) %>% ggplot(aes(x=reorder(region, -as.numeric(prep_B), median), y=as.numeric(prep_B))) + geom_boxplot() + xlab("Region") + ylab("prep_B")

# prep_C plot
c4 <- teacher_data %>% filter(!is.na(prep_C)) %>% ggplot(aes(x=reorder(region, -as.numeric(prep_C), median), y=as.numeric(prep_C))) + geom_boxplot() + xlab("Region") + ylab("prep_C")

# age plot
c5 <- teacher_data %>% filter(!is.na(age)) %>% ggplot(aes(x=reorder(region, -as.numeric(age), median), y=as.numeric(age))) + geom_boxplot() + xlab("Region") + ylab("Age")

# total_time plot
c6 <- teacher_data %>% filter(!is.na(total_time)) %>% ggplot(aes(x=reorder(region, -as.numeric(total_time), median), y=as.numeric(total_time))) + geom_boxplot() + xlab("Region") + ylab("Total Time Working")

# years_teacher plot

c7 <- teacher_data %>% filter(!is.na(years_teacher)) %>% ggplot(aes(x=reorder(region, -as.numeric(years_teacher), median), y=as.numeric(years_teacher))) + geom_boxplot() + xlab("Region") + ylab("Years Working as Teacher")

# plot them all together for less space taken up 
grid.arrange(c1, c2, c3, c4, c5, c6, c7, ncol=3)
```
```{r}

teacher_data %>% filter(!is.na(years_teacher)) %>% ggplot(aes(x=reorder(region, -as.numeric(years_teacher), median), y=as.numeric(years_teacher))) + geom_boxplot() + xlab("Region") + ylab("Years Working as Teacher")

#gender plot
#NOTE: fix margins
mosaicplot(region ~ gender, data=teacher_data, las=2)
```

For collboration we can see that there is a median response rate of 3 (agree) for all regions, but that they differ in the distribution of quartiles. East Mediterranean's teachers had a quartile of responses in Strongly Agree, while North America, South America, and Western Europe had a quartile of responses in Disagree, and Eastern Europe, Northern Europe, Southern Europe, and Western Pacific had 50% of responses in Agree.

For prep_a, the question that asked teachers whether they  feel prepared for the “content of the subjects that I teach”, we see that East Mediterranean and Western Europe are the slight outliers, with 75% of teachers feeling very well prepared in the former, and more than half the teachers feeling less than very well prepared in the later.

For prep_b, the question that asked teachers whether they feel prepared for the “pedagogy of the subjects I teach”, we see that East Mediterranean and Eastern Europe are the two regions that have "Very Well" rather than "Well" as the median. 

For prep_c, the question that asked teachers whether they feel prepared for the “classroom practice in the subjects that I teach”, the regions are split equally, with East Mediterranean, Eastern Europe, South America, and Southern Europe respondents median "Very Well", and the other 4 regions median "Well"

The median ages across regions range from mid 40s to high 30s, but the middle 50% of the data overlaps across all the regions. The same is true for total time working, which ranges from mid 30s to mid 40s, and years working as teacher, which ranges from mid to late teens. 

(3) We will then look at which variables from part (2) are significant when predicted with region. If any are statistically significant, we will graph sat_avg as a function of that variable for each region.

```{r}
# Check which variables have a significant correlation with region
anova(lm(as.numeric(collab) ~ region, data=teacher_data))
anova(lm(as.numeric(prep_A) ~ region, data=teacher_data))
anova(lm(as.numeric(prep_B) ~ region, data=teacher_data))
anova(lm(as.numeric(prep_C) ~ region, data=teacher_data))
anova(lm(as.numeric(age) ~ region, data=teacher_data))
anova(lm(as.numeric(total_time) ~ region, data=teacher_data))
anova(lm(as.numeric(years_teacher) ~ region, data=teacher_data))
```

It looks like all of the variables vary across regions.

```{r}
# Collab and region LM
summary(lm(sat_avg ~ region*as.numeric(collab), data=teacher_data))

# Collab and region plot
teacher_data %>% filter(!is.na(as.numeric(collab))) %>% ggplot(aes(x=as.numeric(collab), y=as.numeric(sat_avg))) + geom_point(alpha=0.05) + xlab("Collab") + ylab("Sat") + facet_wrap(~region)

# prep_A and region LM
summary(lm(sat_avg ~ region*as.numeric(prep_A), data=teacher_data))

# prep_A and region plot
teacher_data %>% filter(!is.na(as.numeric(prep_A))) %>% ggplot(aes(x=as.numeric(prep_A), y=as.numeric(sat_avg))) + geom_point(alpha=0.05) + xlab("prep_A") + ylab("Sat") + facet_wrap(~region)

# prep_B and region LM
summary(lm(sat_avg ~ region*as.numeric(prep_B), data=teacher_data))

# prep_B and region plot
teacher_data %>% filter(!is.na(as.numeric(prep_B))) %>% ggplot(aes(x=as.numeric(prep_B), y=as.numeric(sat_avg))) + geom_point(alpha=0.05) + xlab("prep_B") + ylab("Sat") + facet_wrap(~region)

# prep_C and region LM
summary(lm(sat_avg ~ region*as.numeric(prep_C), data=teacher_data))

# prep_C and region plot
teacher_data %>% filter(!is.na(as.numeric(prep_C))) %>% ggplot(aes(x=as.numeric(prep_C), y=as.numeric(sat_avg))) + geom_point(alpha=0.05) + xlab("prep_C") + ylab("Sat") + facet_wrap(~region)

# age and region LM
summary(lm(sat_avg ~ region*as.numeric(age), data=teacher_data))

# age and region plot
teacher_data %>% filter(!is.na(as.numeric(age))) %>% ggplot(aes(x=as.numeric(age), y=as.numeric(sat_avg))) + geom_point(alpha=0.05) + xlab("Age") + ylab("Sat") + facet_wrap(~region)

# total_time and region LM
summary(lm(sat_avg ~ region*as.numeric(total_time), data=teacher_data))

# total_time and region plot
teacher_data %>% filter(!is.na(as.numeric(total_time))) %>% ggplot(aes(x=as.numeric(total_time), y=as.numeric(sat_avg))) + geom_point(alpha=0.05) + xlab("Total Time Working") + ylab("Sat") + facet_wrap(~region)

# years_working and region LM
# years_teacher and region LM
summary(lm(sat_avg ~ region*as.numeric(years_teacher), data=teacher_data))

# years_teacher and region plot
teacher_data %>% filter(!is.na(as.numeric(years_teacher))) %>% ggplot(aes(x=as.numeric(years_teacher), y=as.numeric(sat_avg))) + geom_point(alpha=0.05) + xlab("Years Working As Teacher") + ylab("Sat") + facet_wrap(~region)
```


(2) TODO
(3) TODO

#### One-way ANOVA Test

After the analysis above is completed, we'll run an ANOVA test to see if there are statistically significant variances in mean `sat_avg` across regions.

```{r}
# Regression of sat_avg vs region
msatreg <- lm(sat_avg ~ region, data=teacher_data)
summary(msatreg)

# ANOVA of regression
anova(msatreg)
```

We will also see if there are statistically significant variances across regions in any of the significant predictors from part (1) that were particularly predictive of teacher satisfaction.

```{r}
# Template code for anova of predictor against region TODO: switch collab with predictive factors after found:
mcollabreg <- lm(collab ~ region, data=teacher_data)
anova(msatreg)
```


For the appendix, we should have the data cleaning code "to be complete" according to Piazza

```{r,eval=FALSE}
# Lower-secondary-school teacher data (international file, all countries) is the file titled BTGINTT2
lower_second_data <- read.spss("SPSS_International/BTGINTT2.sav", to.data.frame=TRUE, use.missings=TRUE)

cols <- c("CNTRY", "TT2G01", "TT2G02", "TT2G05B", "TT2G11", "TT2G13A", "TT2G13B", "TT2G13C", "TT2G16", "TT2G30G", "TT2G38", "TT2G44E", "TJOBSATS")

# We are creating a dataset with the columns from our project proposal, the 10 questions related to job satisfaction, which are columns TT2G46A through TT2G46J, as well as a few additional columns which we also think might be useful
data <- cbind(lower_second_data[,cols],lower_second_data[,grep("TT2G46", colnames(lower_second_data))], lower_second_data[,grep("TT2G15", colnames(lower_second_data))])
```


```{r,eval=FALSE}
# Rename some of the columns so that they're easier to work with
data <- data %>% rename(gender=TT2G01, age=TT2G02, country=CNTRY, years_teacher = TT2G05B, train_stat = TT2G11, prep_A=TT2G13A, prep_B=TT2G13B, prep_C=TT2G13C, total_time=TT2G16, feedback_salary=TT2G30G, collab=TT2G44E, num_students=TT2G38, satisfaction=TJOBSATS)

# Columns that start with TT2G15 correspond to several questions asking what subjects teachers teach:
#Let's manipulate the subject data so that it's in a form that's useful to us

# First make an ID column to merge back after isolating the subject as one column
data$ID <- seq.int(nrow(data))

# Indices of columns dealing with subject taught
indices <- grep("TT2G15", colnames(data))[-1] #-1 to deal with the TT2G15 column that isn't for a specific subject

# Convert "Yes" "No" levels to 0 for didn't teach subject and 1 for taught subject
for (i in indices) {
  data[,i] <- 2 - as.numeric(data[,i])
}

# Rename columns by subject
data <- data %>% rename(R_WR_Lit=TT2G15A, Math=TT2G15B, Science=TT2G15C, Soc_Studies = TT2G15D, For_Lang = TT2G15E, Gk_Ln=TT2G15F, Tech=TT2G15G, Arts=TT2G15H, PE=TT2G15I, Rel_Ethics=TT2G15J, Practical=TT2G15K, Other=TT2G15L)

# Names of columns 
col_names <- colnames(data)[indices]
```

```{r,eval=FALSE}
# Below is just the R code for extracting the subject column
# This is separated for clarity since it is extensive in and of itself

df <- data[25:37]

# Melt to format -- similar to "gather"
temp_by_subj <- melt(df,id="ID")

# Only keep 1's (subjects taught)
temp_by_subj <- temp_by_subj[which(temp_by_subj$value==1),]

# Merge the subject table in with data
data_by_subject <- merge(data,temp_by_subj,all.y=T, by = "ID")

# Clean up unnecessary columns
data_by_subject <- data_by_subject[,-(c(15:24,26:37,39))]
data_by_subject <- data_by_subject %>% rename(Subject=variable)
```

```{r,eval=FALSE}
#Below is the code used to clean up the satisfaction related questions, as well as a few other columns

# All ten columns with responses related to job satisfaction are factors, with 4 levels: "Strongly Disagree", "Disagree", "Agree", "Strongly Agree".
# We are going to convert these 10 columns to numerical data, where the factors get converted to the integers 1, 2, 3, and 4, with 1 corresponding to Strongly Disagree and 4 corresponding to Strongly Agree.
for (i in grep("TT2G46", colnames(data))) {
  data[,i] <- as.numeric(data[,i])
}

# Questions C, D, and F were negatively phrased questions, so we are reversing their scales so we can compare them to the positively phrased questions.
data$TT2G46C <- 5 - data$TT2G46C
data$TT2G46D <- 5 - data$TT2G46D
data$TT2G46F <- 5 - data$TT2G46F

# Questions TT2G46A through J were all related to teacher satisfaction.  Consequently, we are going to create a column that averages the results of these 10 questions to get a sense of teacher satisfaction
data$TT2G46_avg <- rowMeans(data[,grep("TT2G46", colnames(data))], na.rm=TRUE)

# Clean up country column, which has a lot of whitespace
data$country <- as.factor(trimws(as.character(data$country)))

# Clean up train_stat variable so it's easier to work with
# Make No the first factor, so that if we convert it to numeric, it's easy to have 0 represent No and 1 represent Yes
data$train_stat <- relevel(data$train_stat, "No")
```

Let's see how much of the R-squared in our model from part 1 was due to just the country predictor:
```{r}
m_countryonly <- lm(I(sat_avg^2) ~ country, data=x.new)
summary(m_countryonly)
```
0.08257/0.2474 is roughly 33.4%, therefore the country variable alone accounts for 33% of the variability that our final model in Part 1 was able to explain.

# Conclusion:
